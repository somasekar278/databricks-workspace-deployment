# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  ğŸ”§ CENTRAL CONFIGURATION FILE - EXAMPLE                             â•‘
# â•‘                                                                       â•‘
# â•‘  Copy this file to config.yaml and edit with your settings           â•‘
# â•‘  Command: cp config.yaml.example config.yaml                         â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ============================================================================
# AWS Configuration
# ============================================================================
aws:
  region: "us-east-1"              # Your AWS region
  profile: "default"                # Your AWS CLI profile name
  account_id: "123456789012"        # Auto-detected, but you can override

# ============================================================================
# Databricks Configuration
# ============================================================================
databricks:
  account_id: "your-databricks-account-id"  # Get from Databricks Admin Console
  
  # Service Principal (for Terraform - account level)
  service_principal:
    client_id: "your-sp-client-id"
    # Secret stored in AWS Secrets Manager: databricks/service-principal
  
  # Service Principal OAuth (for Application - workspace level)
  oauth:
    client_id: "your-sp-client-id"
    # Secret stored in AWS Secrets Manager: databricks/{workspace_name}/sp-oauth

# ============================================================================
# Workspace Configuration
# ============================================================================
workspace:
  name: "my-workspace"              # Your workspace name
  deployment_name: "my-workspace"   # Deployment name (usually same as workspace name)
  prefix: "my-workspace"            # Prefix for all AWS resources
  
  # VPC Configuration
  vpc:
    use_existing: true              # true = use existing VPC, false = create new
    vpc_id: "vpc-xxxxx"             # Your VPC ID (if use_existing = true)
    subnet_ids:                     # Your subnet IDs (if use_existing = true)
      - "subnet-xxxxx"
      - "subnet-yyyyy"
    security_group_ids:             # Your security group IDs (if use_existing = true)
      - "sg-xxxxx"
  
  # Resource tags (applied to all AWS resources)
  tags:
    ManagedBy: "Terraform"
    Environment: "Development"       # Development, Staging, Production
    Owner: "your.email@company.com"
    Project: "Your-Project-Name"

# ============================================================================
# Unity Catalog Configuration
# ============================================================================
unity_catalog:
  # Create new UC metastore or use existing
  create_metastore: true
  metastore_name: "my-uc-metastore"
  default_catalog_name: "main"
  
  # Additional catalogs to create
  catalogs:
    - name: "analytics"
      comment: "Analytics Catalog"
    - name: "ml"
      comment: "Machine Learning Catalog"
  
  # Schemas to create (under the catalogs above)
  schemas:
    - catalog_name: "analytics"
      name: "sales"
      comment: "Sales Data Schema"
    - catalog_name: "ml"
      name: "models"
      comment: "ML Models Schema"
  
  # Volumes to create (for unstructured data)
  volumes:
    - catalog_name: "analytics"
      schema_name: "sales"
      name: "raw_data"
      comment: "Raw data files"

# ============================================================================
# Lakebase (PostgreSQL) Configuration
# ============================================================================
lakebase:
  # Database instances to create
  instances:
    - name: "my-lakebase-instance"
      capacity: "CU_2"              # Options: CU_2, CU_4, CU_8, CU_16
      enable_pg_native_login: true
  
  # Database catalogs (UC registration + database creation)
  catalogs:
    - name: "my_lakebase_catalog"
      database_instance_name: "my-lakebase-instance"
      database_name: "my_database"
      create_database_if_not_exists: true
  
  # PostgreSQL admin user credentials
  admin_user:
    username: "admin"
    password: "ChangeMe123!"        # âš ï¸ Change this for production!
  
  # Application database schema
  database:
    name: "my_database"
    schema: "app_schema"

# ============================================================================
# User Management Configuration
# ============================================================================
users:
  # Users to create/add to workspace
  users:
    - user_name: "your.email@company.com"
      display_name: "Your Name"
      groups:
        - "Data Engineers"
        - "admins"                  # Built-in admin group (makes user workspace admin)
    
    - user_name: "another.user@company.com"
      display_name: "Another User"
      groups:
        - "Data Engineers"
  
  # Custom groups to create
  groups:
    - display_name: "Data Engineers"
    - display_name: "Data Scientists"
    - display_name: "Analysts"

# ============================================================================
# Application Configuration (Fraud Case Management)
# ============================================================================
application:
  name: "my-fraud-case-management"
  description: "Fraud Case Management Application"
  
  # Node.js settings
  node:
    env: "production"               # production, development
    port: 8000
  
  # Database connection (uses Lakebase config above)
  # These will be auto-populated from lakebase section

# ============================================================================
# Databricks Apps Configuration (Terraform-managed)
# ============================================================================
apps:
  # Apps to create and manage via Terraform
  apps:
    - name: "my-fraud-case-management"
      description: "Fraud Case Management Application"
      source_code_path: "/Workspace/fraud-case-management-app"
      deployment_mode: "SNAPSHOT"  # Options: SNAPSHOT, AUTO_SYNC
    
    # Additional app examples:
    # - name: "my-analytics-app"
    #   description: "Analytics Dashboard App"
    #   source_code_path: "/Workspace/analytics-app"
    #   deployment_mode: "AUTO_SYNC"
    
    # - name: "my-data-app"
    #   description: "Data Processing App"
    #   source_code_path: "/Workspace/data-app"
    #   deployment_mode: "SNAPSHOT"

# ============================================================================
# AWS Secrets Manager Configuration
# ============================================================================
secrets:
  # Secret names in AWS Secrets Manager
  terraform_sp: "databricks/service-principal"
  oauth_sp: "databricks/{workspace_name}/sp-oauth"

# ============================================================================
# INSTRUCTIONS:
# ============================================================================
# 1. Copy this file: cp config.yaml.example config.yaml
# 2. Edit config.yaml with your specific settings
# 3. Store Service Principal credentials in AWS Secrets Manager:
#
#    aws secretsmanager create-secret \
#      --name "databricks/service-principal" \
#      --secret-string '{"client_id":"YOUR_ID","client_secret":"YOUR_SECRET","account_id":"YOUR_ACCOUNT"}' \
#      --region YOUR_REGION
#
# 4. Run: ./configure.sh to generate all config files
# 5. Run: ./deploy-everything.sh to deploy

