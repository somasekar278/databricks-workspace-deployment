#!/bin/bash
# ğŸ”§ Configuration Generator
# Reads config.yaml and generates all necessary configuration files
#
# Usage: ./configure.sh

set -e

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${BLUE}â•‘  ğŸ”§ Configuration Generator                                   â•‘${NC}"
echo -e "${BLUE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Check if config.yaml exists
if [ ! -f "config.yaml" ]; then
    echo -e "${RED}âŒ Error: config.yaml not found!${NC}"
    echo "Please create config.yaml with your settings."
    exit 1
fi

# Check if yq is installed
if ! command -v yq &> /dev/null; then
    echo -e "${YELLOW}âš ï¸  yq not found. Installing...${NC}"
    brew install yq
fi

echo -e "${GREEN}ğŸ“– Reading configuration from config.yaml...${NC}"
echo ""

# Read values from config.yaml
AWS_REGION=$(yq '.aws.region' config.yaml)
AWS_PROFILE=$(yq '.aws.profile' config.yaml)
DATABRICKS_ACCOUNT_ID=$(yq '.databricks.account_id' config.yaml)
WORKSPACE_NAME=$(yq '.workspace.name' config.yaml)
WORKSPACE_DEPLOYMENT_NAME=$(yq '.workspace.deployment_name' config.yaml)
WORKSPACE_PREFIX=$(yq '.workspace.prefix' config.yaml)
UC_METASTORE_NAME=$(yq '.unity_catalog.metastore_name' config.yaml)
CREATE_UC_METASTORE=$(yq '.unity_catalog.create_metastore' config.yaml)
DEFAULT_CATALOG_NAME=$(yq '.unity_catalog.default_catalog_name' config.yaml)
USE_EXISTING_VPC=$(yq '.workspace.vpc.use_existing' config.yaml)
EXISTING_VPC_ID=$(yq '.workspace.vpc.vpc_id' config.yaml)
LAKEBASE_INSTANCE_NAME=$(yq '.lakebase.instances[0].name' config.yaml)
LAKEBASE_CAPACITY=$(yq '.lakebase.instances[0].capacity' config.yaml)
LAKEBASE_DB_NAME=$(yq '.lakebase.catalogs[0].database_name' config.yaml)
DB_ADMIN_USER=$(yq '.lakebase.admin_user.username' config.yaml)
DB_ADMIN_PASSWORD=$(yq '.lakebase.admin_user.password' config.yaml)
DB_SCHEMA=$(yq '.lakebase.database.schema' config.yaml)
APP_NAME=$(yq '.application.name' config.yaml)
APP_PORT=$(yq '.application.node.port' config.yaml)
OAUTH_CLIENT_ID=$(yq '.databricks.oauth.client_id' config.yaml)

echo -e "${GREEN}âœ… Configuration loaded successfully!${NC}"
echo ""

# ============================================
# Generate terraform.tfvars
# ============================================
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${GREEN}ğŸ“ Generating terraform.tfvars...${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

cat > terraform.tfvars << EOF
# Generated by configure.sh from config.yaml
# Do not edit this file directly - edit config.yaml instead

# AWS Configuration
aws_region  = "$AWS_REGION"
aws_profile = "$AWS_PROFILE"

# Databricks Configuration
databricks_account_id     = "$DATABRICKS_ACCOUNT_ID"
workspace_name            = "$WORKSPACE_NAME"
workspace_deployment_name = "$WORKSPACE_DEPLOYMENT_NAME"
workspace_prefix          = "$WORKSPACE_PREFIX"

# VPC Configuration
use_existing_vpc = $USE_EXISTING_VPC
EOF

if [ "$USE_EXISTING_VPC" = "true" ]; then
    SUBNET_IDS=$(yq '.workspace.vpc.subnet_ids' config.yaml -o=json)
    SG_IDS=$(yq '.workspace.vpc.security_group_ids' config.yaml -o=json)
    
    cat >> terraform.tfvars << EOF
existing_vpc_id            = "$EXISTING_VPC_ID"
existing_subnet_ids        = $SUBNET_IDS
existing_security_group_ids = $SG_IDS
EOF
fi

# Unity Catalog
cat >> terraform.tfvars << EOF

# Unity Catalog Configuration
create_uc_metastore  = $CREATE_UC_METASTORE
uc_metastore_name    = "$UC_METASTORE_NAME"
default_catalog_name = "$DEFAULT_CATALOG_NAME"

# Unity Catalog Objects
EOF

yq '.unity_catalog.catalogs' config.yaml -o=json | jq -c 'map({name: .name, comment: .comment})' | \
    awk '{print "uc_catalogs = " $0}' >> terraform.tfvars

yq '.unity_catalog.schemas' config.yaml -o=json | jq -c 'map({catalog_name: .catalog_name, name: .name, comment: .comment})' | \
    awk '{print "uc_schemas = " $0}' >> terraform.tfvars

yq '.unity_catalog.volumes' config.yaml -o=json | jq -c 'map({catalog_name: .catalog_name, schema_name: .schema_name, name: .name, comment: .comment})' | \
    awk '{print "uc_volumes = " $0}' >> terraform.tfvars

# Lakebase
cat >> terraform.tfvars << EOF

# Lakebase Configuration
EOF

yq '.lakebase.instances' config.yaml -o=json | jq -c 'map({name: .name, capacity: .capacity, enable_pg_native_login: .enable_pg_native_login})' | \
    awk '{print "lakebase_database_instances = " $0}' >> terraform.tfvars

yq '.lakebase.catalogs' config.yaml -o=json | jq -c 'map({name: .name, database_instance_name: .database_instance_name, database_name: .database_name, create_database_if_not_exists: .create_database_if_not_exists})' | \
    awk '{print "lakebase_database_catalogs = " $0}' >> terraform.tfvars

# Users and Groups
cat >> terraform.tfvars << EOF

# Users and Groups
EOF

yq '.users.groups' config.yaml -o=json | jq -c 'map({display_name: .display_name})' | \
    awk '{print "groups = " $0}' >> terraform.tfvars

yq '.users.users' config.yaml -o=json | jq -c 'map({user_name: .user_name, display_name: .display_name, groups: .groups})' | \
    awk '{print "users = " $0}' >> terraform.tfvars

# Tags
cat >> terraform.tfvars << EOF

# Tags
EOF

yq '.workspace.tags' config.yaml -o=json | jq -c '.' | \
    awk '{print "tags = " $0}' >> terraform.tfvars

# Apps
cat >> terraform.tfvars << EOF

# Databricks Apps
EOF

yq '.apps.apps' config.yaml -o=json | jq -c 'map({name: .name, description: .description, source_code_path: .source_code_path, deployment_mode: .deployment_mode})' | \
    awk '{print "apps = " $0}' >> terraform.tfvars

echo -e "${GREEN}âœ… terraform.tfvars generated${NC}"
echo ""

# ============================================
# Update fraud-case-management/app.yaml
# ============================================
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${GREEN}ğŸ“ Updating fraud-case-management/app.yaml...${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Get OAuth secret from AWS Secrets Manager
echo "ğŸ” Retrieving OAuth secret from AWS Secrets Manager..."
OAUTH_SECRET=$(aws secretsmanager get-secret-value \
    --secret-id "databricks/$WORKSPACE_NAME/sp-oauth" \
    --region "$AWS_REGION" \
    --profile "$AWS_PROFILE" \
    --query SecretString \
    --output text 2>/dev/null | jq -r '.client_secret' || echo "")

if [ -z "$OAUTH_SECRET" ]; then
    echo -e "${YELLOW}âš ï¸  OAuth secret not found in AWS Secrets Manager${NC}"
    echo "   Using placeholder - you'll need to update this before deploying the app"
    OAUTH_SECRET="YOUR_OAUTH_SECRET_HERE"
fi

# Get Lakebase DNS (from Terraform output if available)
LAKEBASE_DNS=""
if [ -f terraform.tfstate ]; then
    LAKEBASE_DNS=$(terraform output -json lakebase_database_instances 2>/dev/null | \
        jq -r ".[\"$LAKEBASE_INSTANCE_NAME\"].read_write_dns" 2>/dev/null || echo "")
fi

if [ -z "$LAKEBASE_DNS" ]; then
    echo -e "${YELLOW}âš ï¸  Lakebase DNS not found in Terraform state${NC}"
    echo "   Using placeholder - will be updated after infrastructure deployment"
    LAKEBASE_DNS="YOUR_LAKEBASE_DNS_HERE"
fi

WORKSPACE_URL="https://one-env-$WORKSPACE_NAME.cloud.databricks.com"

cat > ../fraud-case-management/app.yaml << EOF
# Generated by configure.sh from config.yaml
# Do not edit this file directly - edit config.yaml instead

command: ["sh", "-c", "cd /app/python/source_code && npm install && npm run build && npm start"]

env:
  # Database Configuration
  - name: DB_HOST
    value: "$LAKEBASE_DNS"
  - name: DB_PORT
    value: "5432"
  - name: DB_NAME
    value: "$LAKEBASE_DB_NAME"
  - name: DB_USER
    value: "$DB_ADMIN_USER"
  - name: DB_PASSWORD
    value: "$DB_ADMIN_PASSWORD"
  - name: DB_SSL
    value: "true"
  
  # Node.js Configuration
  - name: NODE_ENV
    value: "production"
  - name: PORT
    value: "$APP_PORT"
  
  # Databricks OAuth Configuration
  - name: DATABRICKS_HOST
    value: "$WORKSPACE_URL"
  - name: DATABRICKS_CLIENT_ID
    value: "$OAUTH_CLIENT_ID"
  - name: DATABRICKS_CLIENT_SECRET
    value: "$OAUTH_SECRET"
EOF

echo -e "${GREEN}âœ… app.yaml updated${NC}"
echo ""

# ============================================
# Create environment file for scripts
# ============================================
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo -e "${GREEN}ğŸ“ Creating .env file for scripts...${NC}"
echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

cat > .env << EOF
# Generated by configure.sh from config.yaml
# Source this file in scripts: source .env

# AWS Configuration
export AWS_REGION="$AWS_REGION"
export AWS_PROFILE="$AWS_PROFILE"

# Databricks Configuration
export DATABRICKS_ACCOUNT_ID="$DATABRICKS_ACCOUNT_ID"
export WORKSPACE_NAME="$WORKSPACE_NAME"
export WORKSPACE_URL="$WORKSPACE_URL"

# Lakebase Configuration
export LAKEBASE_INSTANCE_NAME="$LAKEBASE_INSTANCE_NAME"
export LAKEBASE_DB_NAME="$LAKEBASE_DB_NAME"
export DB_ADMIN_USER="$DB_ADMIN_USER"
export DB_ADMIN_PASSWORD="$DB_ADMIN_PASSWORD"
export DB_SCHEMA="$DB_SCHEMA"

# Application Configuration
export APP_NAME="$APP_NAME"
EOF

echo -e "${GREEN}âœ… .env file created${NC}"
echo ""

# ============================================
# Summary
# ============================================
echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${GREEN}â•‘  âœ… Configuration Complete!                                   â•‘${NC}"
echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""
echo -e "${BLUE}ğŸ“‹ Generated Files:${NC}"
echo "   âœ… terraform.tfvars"
echo "   âœ… fraud-case-management/app.yaml"
echo "   âœ… .env (for scripts)"
echo ""
echo -e "${YELLOW}ğŸ“ Configuration Summary:${NC}"
echo "   Workspace: $WORKSPACE_NAME"
echo "   UC Metastore: $UC_METASTORE_NAME"
echo "   Lakebase Instance: $LAKEBASE_INSTANCE_NAME"
echo "   Application: $APP_NAME"
echo ""
echo -e "${GREEN}ğŸš€ Next Steps:${NC}"
echo "   1. Review generated files (terraform.tfvars, app.yaml)"
echo "   2. Run: ./deploy-everything.sh"
echo ""

